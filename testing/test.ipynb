{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from ctm_dataloader import create_dataloader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (11314, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "\n",
       "            target_names  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data = pd.read_csv(\"newsgroups_data.csv\")\n",
    "print(\"Shape of dataset:\", news_data.shape)\n",
    "\n",
    "news_data = news_data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "documents = news_data.content\n",
    "target_labels = news_data.target\n",
    "target_names = news_data.target_names\n",
    "\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "num_topics = 5\n",
    "batch_size = 64\n",
    "rho_size = 5\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing vocabulary:\n",
      "['also' 'article' 'believe' 'call' 'come' 'drive' 'even' 'file' 'find'\n",
      " 'first']\n",
      "Shape of the bag-of-words model: (11314, 50)\n",
      "Shape of data: torch.Size([64, 50])\n"
     ]
    }
   ],
   "source": [
    "# Create dataloader\n",
    "train_loader, vocab_size = create_dataloader(documents, batch_size)\n",
    "\n",
    "for idx, data in enumerate(train_loader):\n",
    "    print(\"Shape of data:\", data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTM(nn.Module):\n",
    "    def __init__(self, num_topics, vocab_size, rho_size):\n",
    "        super(CTM, self).__init__()\n",
    "        self.num_topics = num_topics\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rho_size = rho_size\n",
    "\n",
    "        # Parameters for document-topic distribution\n",
    "        self.alpha = nn.Parameter(torch.randn(num_topics))\n",
    "\n",
    "        # Parameters for topic-word distribution\n",
    "        self.beta = nn.Parameter(torch.randn(num_topics, vocab_size))\n",
    "\n",
    "        # Fixed parameters for the Gaussian distribution of the correlation matrix\n",
    "        self.mu = nn.Parameter(torch.zeros(num_topics))\n",
    "        self.sigma = nn.Parameter(torch.ones(num_topics, num_topics))\n",
    "\n",
    "    def forward(self, bow):\n",
    "        # Calculate document-topic distribution using the softmax function\n",
    "        theta = F.softmax(self.alpha, dim=0)\n",
    "\n",
    "        # Calculate topic-word distribution using the softmax function\n",
    "        phi = F.softmax(self.beta, dim=1)\n",
    "\n",
    "        # Sample correlation matrix from a Gaussian distribution\n",
    "        rho = torch.randn_like(self.mu) * self.sigma + self.mu\n",
    "        sigma = torch.mm(rho, rho.t())\n",
    "\n",
    "        # Calculate the document-topic distribution for each document in the batch\n",
    "        # doc_topic_dist = torch.mm(torch.mm(bow, phi.t()), torch.diag(theta))\n",
    "        doc_topic_dist = torch.mm(bow, torch.mm(theta.diag(), phi).t()).type(torch.LongTensor)\n",
    "\n",
    "        return doc_topic_dist, theta, phi, sigma\n",
    "\n",
    "    def ctm_loss(self, doc_topic_dist, bow, theta, phi, sigma):\n",
    "        # Reconstruction loss\n",
    "        recon_loss = -torch.sum(bow * torch.log(doc_topic_dist + 1e-9))\n",
    "\n",
    "        # Regularization terms\n",
    "        alpha_reg = -0.5 * torch.sum(theta * theta)\n",
    "        beta_reg = -0.5 * torch.sum(phi * phi)\n",
    "        rho_reg = -0.5 * torch.sum(sigma * sigma)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = recon_loss + alpha_reg + beta_reg + rho_reg\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def train_ctm(self, model, dataloader, optimizer, num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0.0\n",
    "\n",
    "            for idx, bow in enumerate(dataloader):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                print(f'Forward pass number {idx + 1}')\n",
    "                doc_topic_dist, theta, phi, sigma = model(bow)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = self.ctm_loss(doc_topic_dist, bow, theta, phi, sigma)\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CTM(num_topics, vocab_size, rho_size)\n",
    "\n",
    "# Hyper parameters for the model\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass number 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Model training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mtrain_ctm(model, train_loader, optimizer, num_epochs)\n",
      "\u001b[1;32m/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mForward pass number \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m doc_topic_dist, theta, phi, sigma \u001b[39m=\u001b[39m model(bow)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Calculate loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctm_loss(doc_topic_dist, bow, theta, phi, sigma)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m sigma \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(rho, rho\u001b[39m.\u001b[39mt())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Calculate the document-topic distribution for each document in the batch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# doc_topic_dist = torch.mm(torch.mm(bow, phi.t()), torch.diag(theta))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m doc_topic_dist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(bow, torch\u001b[39m.\u001b[39mmm(theta\u001b[39m.\u001b[39mdiag(), phi)\u001b[39m.\u001b[39mt())\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anugrahvaishnav/Desktop/Correlated-Topic-Modeling-In-Pytorch/test.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mreturn\u001b[39;00m doc_topic_dist, theta, phi, sigma\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "model.train_ctm(model, train_loader, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.2794e-02, -5.9271e-02,  7.9860e-02, -5.3417e-02, -5.0754e-02],\n",
       "        [-1.5863e-02, -7.2526e-02, -1.0251e-01, -1.6956e-02, -1.5346e-03],\n",
       "        [-1.7118e-03, -4.6495e-02, -6.8183e-02,  1.3756e-02,  3.6790e-02],\n",
       "        [ 1.4866e-02,  8.1127e-02, -8.0783e-02, -2.6623e-02, -5.9851e-02],\n",
       "        [-5.8799e-02,  9.6068e-03, -5.7787e-03, -1.8282e-02,  3.1468e-02],\n",
       "        [ 2.1975e-03, -4.4036e-02,  3.9203e-03, -2.6338e-02, -6.7144e-03],\n",
       "        [-6.2016e-02, -4.2894e-02, -2.4982e-01, -1.9733e-03, -1.4236e-02],\n",
       "        [-1.4666e-02, -5.3935e-02, -1.7326e-01, -1.0494e-02, -1.9817e-02],\n",
       "        [ 6.0686e-02, -8.4007e-03, -1.2442e-01, -3.4783e-03, -8.7673e-04],\n",
       "        [-2.8180e-02, -1.0351e-01,  7.0084e-02,  1.6225e-02,  1.2218e-02],\n",
       "        [ 6.5545e-03, -6.3201e-02, -2.2912e-02, -3.2435e-03,  2.7094e-02],\n",
       "        [ 3.6090e-02, -5.2901e-02, -1.0103e-01, -2.6638e-02,  4.1363e-02],\n",
       "        [-1.1474e-02, -6.2607e-03, -1.2875e-01, -4.2854e-02, -1.2747e-02],\n",
       "        [ 1.6749e-02, -7.0734e-02, -1.8876e-01,  1.9885e-03, -1.6278e-02],\n",
       "        [ 5.9704e-02, -6.7636e-02,  1.1449e-01, -1.7817e-02, -7.6866e-04],\n",
       "        [ 3.3223e-02,  1.6831e-02, -1.0394e-01,  2.8269e-02,  5.9148e-03],\n",
       "        [ 7.2382e-03,  5.5910e-02,  9.8585e-02, -5.7910e-03, -2.6303e-02],\n",
       "        [ 2.9515e-02, -2.9548e-02,  6.4834e-02, -1.4777e-02,  5.1887e-02],\n",
       "        [ 5.2982e-02,  1.8605e-02,  2.1946e-01,  1.2890e-02,  2.3845e-02],\n",
       "        [ 2.9136e-02,  5.1568e-02,  2.7015e-01,  4.5051e-03,  4.6992e-02],\n",
       "        [-1.8132e-02, -3.2451e-02, -1.2248e-01, -1.5110e-02, -4.3256e-03],\n",
       "        [-2.4539e-02,  4.9118e-02, -1.5009e-01, -1.0231e-03,  3.2918e-02],\n",
       "        [ 3.3571e-02, -4.1211e-02, -9.3036e-02, -3.5749e-02, -2.7871e-02],\n",
       "        [-3.8059e-03, -7.2307e-02,  8.5889e-02,  1.7768e-02, -6.4171e-03],\n",
       "        [ 7.8834e-03,  6.2439e-02,  1.0329e-02,  1.3741e-02,  4.8981e-02],\n",
       "        [ 2.4568e-02, -3.9761e-02,  5.2845e-02, -4.9925e-02,  1.7050e-02],\n",
       "        [-4.5986e-02, -6.5478e-02,  1.1221e-02, -1.7758e-02,  3.3447e-03],\n",
       "        [-2.6913e-02, -1.3973e-02, -1.5931e-01,  1.5806e-02, -5.6746e-02],\n",
       "        [-4.7667e-02, -7.1167e-02, -2.4886e-01, -3.2342e-02,  3.9907e-03],\n",
       "        [-4.6008e-03, -9.5027e-02, -9.6239e-03,  1.6916e-02, -4.6376e-02],\n",
       "        [-2.6147e-02, -7.5436e-02,  5.7894e-02,  1.4164e-02,  1.3593e-02],\n",
       "        [ 2.6317e-02,  2.6048e-02, -4.3059e-02,  2.2268e-02, -2.6830e-04],\n",
       "        [-4.0439e-02, -1.7790e-02,  7.3483e-03,  2.4361e-02,  4.1181e-02],\n",
       "        [ 2.8707e-02,  3.9981e-02,  3.1698e-02,  1.2054e-02, -3.1779e-02],\n",
       "        [ 6.1530e-02,  6.8234e-02,  5.2265e-02,  5.5769e-03,  2.2705e-02],\n",
       "        [-2.2612e-03, -4.8569e-02,  1.0967e-01,  2.0483e-02,  4.1543e-02],\n",
       "        [ 1.3294e-02, -1.6697e-02, -7.8943e-02, -4.5149e-02, -3.9001e-02],\n",
       "        [-3.1471e-02,  6.7355e-03,  2.3806e-01,  2.6372e-02,  6.2288e-02],\n",
       "        [-1.6969e-02,  7.4098e-02,  7.9209e-03,  1.0090e-02,  2.7705e-02],\n",
       "        [-2.8123e-02, -2.8075e-02,  2.4980e-02,  2.0669e-02,  1.2811e-02],\n",
       "        [-1.1599e-02,  2.4799e-02,  1.2000e-01, -1.8729e-02, -8.8009e-03],\n",
       "        [-3.5582e-02,  2.2227e-02, -8.4471e-03, -1.8442e-02, -2.0834e-02],\n",
       "        [ 2.7501e-02, -4.7139e-02, -2.5219e-02,  6.6522e-03,  4.3441e-02],\n",
       "        [-1.3602e-02, -1.2343e-03, -5.7004e-02,  1.1257e-02,  4.9966e-02],\n",
       "        [ 1.2880e-02, -3.7346e-02, -3.1004e-02,  2.4104e-03, -8.2887e-03],\n",
       "        [-2.1826e-02, -5.8098e-02,  1.0972e-01, -2.7146e-02, -9.6838e-02],\n",
       "        [ 5.0224e-03, -1.2162e-02, -2.0025e-01, -4.8225e-02, -6.3507e-02],\n",
       "        [ 2.1164e-02,  4.3409e-02, -2.6703e-01,  4.1948e-02,  2.2349e-02],\n",
       "        [-2.6241e-02, -1.7667e-02, -8.4236e-02,  7.3568e-03, -5.0879e-03],\n",
       "        [-2.4891e-02, -3.3350e-02, -1.5177e-01, -1.0590e-02, -4.3322e-02],\n",
       "        [ 7.8416e-03,  4.0336e-02, -4.6761e-03, -2.9890e-02, -3.2959e-02],\n",
       "        [-2.0706e-02,  3.1306e-02, -1.6634e-01, -4.0125e-02, -3.3616e-02],\n",
       "        [ 2.6791e-02,  5.1894e-02,  1.1180e-01,  1.2535e-03,  2.2069e-02],\n",
       "        [ 1.1466e-02, -1.4175e-02, -2.5005e-02, -7.3585e-03, -1.2763e-02],\n",
       "        [-1.4530e-02, -1.4125e-01, -4.9587e-02, -4.6957e-02, -3.7181e-02],\n",
       "        [-2.4681e-02,  1.4431e-02,  6.9341e-02,  2.5119e-02,  4.5924e-02],\n",
       "        [ 4.3898e-02,  1.0517e-01, -2.9572e-02,  2.9837e-02, -1.6483e-02],\n",
       "        [ 2.0147e-02,  1.1720e-01,  1.3854e-01,  2.3902e-02,  5.1674e-02],\n",
       "        [-2.8144e-03,  6.3438e-03, -1.8169e-02, -1.1999e-02, -4.5652e-02],\n",
       "        [-2.4019e-03, -1.7166e-02, -2.4900e-02,  1.5997e-02, -1.9846e-02],\n",
       "        [ 1.6876e-02, -2.9490e-02,  1.2101e-01,  2.2047e-02, -4.7361e-03],\n",
       "        [ 2.2993e-02, -8.4373e-03, -1.0867e-01,  9.4909e-03,  5.0039e-02],\n",
       "        [ 9.1094e-03, -1.3700e-01, -7.3147e-02, -5.7934e-02, -7.9287e-02],\n",
       "        [-3.5438e-02,  9.7722e-02,  1.6717e-03, -2.3508e-02, -2.0700e-02]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = nn.Parameter(torch.randn(num_topics))\n",
    "beta = nn.Parameter(torch.randn(num_topics, vocab_size))\n",
    "\n",
    "theta = F.softmax(alpha, dim=0)\n",
    "phi = F.softmax(beta, dim=1)\n",
    "bow = torch.randn(64, vocab_size)\n",
    "\n",
    "torch.mm(bow, torch.mm(theta.diag(), phi).t())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSIT5670",
   "language": "python",
   "name": "msit5670"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
